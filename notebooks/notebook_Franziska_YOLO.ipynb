{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Franziska \n",
    "Trained with Vertex AI and not locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ultralytics\n",
    "#w!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import PIL\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib.patches import Rectangle, Polygon\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "base_path = \"/home/jupyter/Remote Sensing Data.v2i.yolov8\"\n",
    "yaml_path = base_path + \"/data.yaml\"\n",
    "test_images_path = base_path + \"/test/images\"\n",
    "predicted_images_path = \"/home/jupyter/runs/detect\"\n",
    "log_dir = \"/home/jupyter/runs/detect/train\"  # Adjust this path based on your setup\n",
    "\n",
    "# Define data paths\n",
    "data_path = \"/home/jupyter/Remote Sensing Data.v2i.yolov8\"\n",
    "train_path = os.path.join(data_path, 'train')\n",
    "val_path = os.path.join(data_path, 'val')\n",
    "\n",
    "\n",
    "base_model = \"yolov8n.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory\n",
    "labels_path = os.path.join(base_path, 'train/labels')\n",
    "images_path = os.path.join(base_path, 'train/images')\n",
    "\n",
    "# Class labels from data.yaml\n",
    "labels = ['Agriculture', 'Airport', 'Beach', 'City', 'Desert', 'Forest', 'Grassland', 'Highway', 'Lake', 'Mountain', 'Parking', 'Port', 'Railway', 'River']\n",
    "# Define a color map for different classes\n",
    "colors = plt.cm.get_cmap('hsv', len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_file):\n",
    "    \"\"\"\n",
    "    Load label data from a .txt file.\n",
    "\n",
    "    Parameters:\n",
    "    label_file (str): Path to the label file\n",
    "\n",
    "    Returns:\n",
    "    list: List of annotations (polygons and rectangles) with classes\n",
    "    \"\"\"\n",
    "    annotations = []\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            try:\n",
    "                class_id = int(parts[0])\n",
    "                if len(parts) == 5:\n",
    "                    # Rectangle: class_id, x_center, y_center, width, height\n",
    "                    xc, yc, w, h = [float(x) for x in parts[1:]]\n",
    "                    annotations.append((class_id, 'rectangle', xc, yc, w, h))\n",
    "                else:\n",
    "                    # Polygon: class_id, x1, y1, x2, y2, ..., xN, yN\n",
    "                    vertices = []\n",
    "                    for i in range(1, len(parts), 2):\n",
    "                        x = float(parts[i])\n",
    "                        y = float(parts[i + 1])\n",
    "                        vertices.append((x, y))\n",
    "                    annotations.append((class_id, 'polygon', vertices))\n",
    "            except ValueError:\n",
    "                continue  # Skip lines with invalid values\n",
    "    return annotations\n",
    "\n",
    "def visualize_annotations(image_file, label_file, ax):\n",
    "    \"\"\"\n",
    "    Visualize annotations (polygons and rectangles) on an image.\n",
    "\n",
    "    Parameters:\n",
    "    image_file (str): Path to the image\n",
    "    label_file (str): Path to the label file\n",
    "    ax (matplotlib.axes._subplots.AxesSubplot): The subplot axis to display the image\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_file)\n",
    "    height, width, _ = image.shape\n",
    "    annotations = load_labels(label_file)\n",
    "\n",
    "    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    ax.set_title(os.path.basename(image_file))\n",
    "\n",
    "    for annotation in annotations:\n",
    "        class_id, annotation_type, *data = annotation\n",
    "\n",
    "        color = colors(class_id)\n",
    "\n",
    "        if annotation_type == 'rectangle':\n",
    "            xc, yc, w, h = data\n",
    "            xmin = int((xc - w / 2) * width)\n",
    "            ymin = int((yc - h / 2) * height)\n",
    "            xmax = int((xc + w / 2) * width)\n",
    "            ymax = int((yc + h / 2) * height)\n",
    "            ax.add_patch(Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, edgecolor=color, fill=False, linewidth=2))\n",
    "            ax.text(xmin, ymin, labels[class_id], bbox={'facecolor': color, 'alpha': 0.5}, fontsize=10, color='white')\n",
    "\n",
    "        elif annotation_type == 'polygon':\n",
    "            vertices = [(x * width, y * height) for x, y in data[0]]\n",
    "            ax.add_patch(Polygon(vertices, closed=True, edgecolor=color, fill=False, linewidth=2))\n",
    "            ax.text(vertices[0][0], vertices[0][1], labels[class_id], bbox={'facecolor': color, 'alpha': 0.5}, fontsize=10, color='white')\n",
    "\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image files\n",
    "image_files = [os.path.join(images_path, f) for f in os.listdir(images_path) if f.endswith('.jpg')]\n",
    "label_files = [os.path.join(labels_path, os.path.splitext(f)[0] + '.txt') for f in os.listdir(images_path) if f.endswith('.jpg')]\n",
    "\n",
    "# Randomly select 9 images and their corresponding labels\n",
    "selected_indices = random.sample(range(len(image_files)), 9)\n",
    "selected_image_files = [image_files[i] for i in selected_indices]\n",
    "selected_label_files = [label_files[i] for i in selected_indices]\n",
    "\n",
    "# Visualize in a 3x3 grid\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "for ax, image_file, label_file in zip(axs.flat, selected_image_files, selected_label_files):\n",
    "    visualize_annotations(image_file, label_file, ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = YOLO(base_model)\n",
    "# Train the model\n",
    "results = model.train(data=os.path.join(data_path, 'data.yaml'), epochs=20, imgsz=640, save=True, fraction=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = YOLO(\"../models/yolov8n.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"/home/franziska/code/FranziskaHaisch/EnviroClass/raw_data/satellite_images_14_classes/data.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "results_val = model.val(data=yaml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the post-training images\n",
    "def display_images(post_training_files_path, image_files):\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(post_training_files_path, image_file)\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(10, 10), dpi=120)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Could not load image: {image_file}\")\n",
    "\n",
    "# List of image files to display\n",
    "image_files = [\n",
    "    'confusion_matrix_normalized.png',\n",
    "    'F1_curve.png',\n",
    "    'P_curve.png',\n",
    "    'R_curve.png',\n",
    "    'PR_curve.png',\n",
    "    'results.png'\n",
    "]\n",
    "\n",
    "# Path to the directory containing the images\n",
    "post_training_files_path = '/home/jupyter/runs/detect/tval'\n",
    "\n",
    "# Display the images\n",
    "display_images(post_training_files_path, image_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on new images\n",
    "predictions = model.predict(source=test_images_path, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of predicted images\n",
    "predicted_images = glob.glob(\"/home/jupyter/runs/detect/predict\" + \"/*.jpg\")\n",
    "\n",
    "# Shuffle the list of images to select 9 random images\n",
    "random.shuffle(predicted_images)\n",
    "\n",
    "# Create a 3x3 grid of images\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "for ax, img_path in zip(axs.flat, predicted_images[:9]):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        print(f\"Could not load image: {img_path}\")  # Debugging info\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnviroClass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
